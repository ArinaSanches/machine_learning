{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = pd.read_csv('iris.csv', names =['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'flower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_multiclass = pd.read_csv('iris_multiclasse.csv', names =['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'flower1','flower2','flower3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(matrix, vector):\n",
    "    #Mean calculation\n",
    "    mVector = np.mean(vector, axis=0)\n",
    "    mMatrix = np.mean(matrix, axis=0)\n",
    "    \n",
    "    #Standard deviation\n",
    "    stdVector = np.std(vector, axis = 0)\n",
    "    stdMatrix = np.std(matrix, axis = 0)\n",
    "     \n",
    "    #Normalization of data\n",
    "    vector = (vector - mVector)/stdVector\n",
    "    matrix = (matrix - mMatrix)/stdMatrix\n",
    "    \n",
    "    return matrix, vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression_binary(matrix_x, w):\n",
    "    \n",
    "    predictions = []\n",
    "    matrix_x = np.insert(matrix_x, 0, 1, axis =1)\n",
    "    for i in range(matrix_x.shape[0]):\n",
    "        predictions.append(round(sigmoide(matrix_x[i].dot(w))))\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiclass_logistic_regression(matrix_x_multiclass, w):\n",
    "    \n",
    "    matrix_x_multiclass = np.insert(matrix_x_multiclass, 0, 1, axis =1)\n",
    "    \n",
    "    size = (matrix_x_multiclass.shape[0], w.shape[0])\n",
    "    predictions = np.ones(size, dtype=float)\n",
    "    \n",
    "    for k in range(w.shape[0]):   \n",
    "        for i in range(matrix_x_multiclass.shape[0]):\n",
    "            num = np.exp(w[k].dot(matrix_x_multiclass[i]))\n",
    "            sum_ = 0\n",
    "            for j in range(w.shape[0]):\n",
    "                sum_ = sum_ + np.exp(w[j].dot(matrix_x_multiclass[i]))\n",
    "            predictions[i][k] = num/sum_\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        index = np.argmax(predictions[i], axis=0)\n",
    "        for j in range(len(predictions[i])):\n",
    "            if(j == index):\n",
    "                predictions[i][index] = 1.0\n",
    "            else:\n",
    "                predictions[i][j] = 0.0\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost(mse):\n",
    "    plt.plot(list(range(0, len(mse))), [item[0] for item in mse])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationSplit(xMatrix, yVector, n_folds): \n",
    "    xMatrixSplit = []\n",
    "    yVectorSplit = []\n",
    "    xMatrixCopy = xMatrix\n",
    "\n",
    "    yVectorCopy = yVector\n",
    "    foldSize = int(len(xMatrix) / n_folds) \n",
    "    \n",
    "    for i in range(n_folds): \n",
    "        foldXM = [] \n",
    "        foldYV = []\n",
    "        while len(foldXM) < foldSize: \n",
    "            index = rd.randrange(len(xMatrixCopy)) \n",
    "            foldXM.append(xMatrixCopy[index]) \n",
    "            xMatrixCopy = np.delete(xMatrixCopy, index, axis=0)\n",
    "            foldYV.append(yVectorCopy[index]) \n",
    "            yVectorCopy = np.delete(yVectorCopy, index)\n",
    "        xMatrixSplit.append(foldXM)\n",
    "        yVectorSplit.append(foldYV)\n",
    "    return xMatrixSplit, yVectorSplit\n",
    "\n",
    "\n",
    "def crossValidationSplitMulticlass(xMatrix, yVector, n_folds): \n",
    "    xMatrixSplit = []\n",
    "    yVectorSplit = []\n",
    "    xMatrixCopy = xMatrix\n",
    "\n",
    "    yVectorCopy = yVector\n",
    "\n",
    "    foldSize = int(len(xMatrix) / n_folds) \n",
    "    \n",
    "    for i in range(n_folds): \n",
    "        foldXM = [] \n",
    "        foldYV = []\n",
    "        while len(foldXM) < foldSize: \n",
    "            index = rd.randrange(len(xMatrixCopy)) \n",
    "            foldXM.append(xMatrixCopy[index]) \n",
    "            xMatrixCopy = np.delete(xMatrixCopy, index, axis=0)\n",
    "            foldYV.append(yVectorCopy[index]) \n",
    "            yVectorCopy = np.delete(yVectorCopy, index,axis=0)\n",
    "        xMatrixSplit.append(foldXM)\n",
    "        yVectorSplit.append(foldYV)\n",
    "\n",
    "    return xMatrixSplit, yVectorSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldCrossValidation(xMatrix, yVector, kParts, algorithm, *args):\n",
    "    xMFolds, yVFolds = crossValidationSplit(xMatrix, yVector, kParts) \n",
    "    scores = list() \n",
    "    count = 0;\n",
    "    for fold in xMFolds: \n",
    "        xTrain = xMFolds\n",
    "        yTrain = yVFolds\n",
    "        \n",
    "        xTest = xTrain[count]\n",
    "        yTest = np.array(yTrain[count])\n",
    "        \n",
    "        np.delete(xTrain,count)\n",
    "        np.delete(yTrain,count)\n",
    "        \n",
    "        yTrain = np.stack(yTrain)\n",
    "        yTrain = yTrain.ravel()\n",
    "        xTrainAux = []\n",
    "\n",
    "        for i in range(kParts):\n",
    "            for j in range(len(xTrain[i])):\n",
    "                xTrainAux.append(xTrain[i][j])\n",
    "        xTrain = np.stack(xTrainAux)\n",
    "        yTest = np.where(yTest < 0, 0, yTest)\n",
    "        predicted = algorithm(xTrain, yTrain, xTest,  *args)\n",
    "        for i in range(len(predicted)):\n",
    "            print(\"Predicted: \",predicted[i],\"Actual: \",yTest[i])\n",
    "        accuracy = np.array([x - y for x, y in zip(predicted, yTest)])/kParts\n",
    "        scores.append(accuracy) \n",
    "    return scores\n",
    "\n",
    "def kFoldCrossValidationMulticlass(xMatrix, yVector, kParts, algorithm, *args):\n",
    "    xMFolds, yVFolds = crossValidationSplitMulticlass(xMatrix, yVector, kParts) \n",
    "    scores = list() \n",
    "    count = 0;\n",
    "    for fold in xMFolds: \n",
    "        xTrain = xMFolds\n",
    "        yTrain = yVFolds\n",
    "        \n",
    "        xTest = xTrain[count]\n",
    "        yTest = np.array(yTrain[count])\n",
    "        \n",
    "        np.delete(xTrain,count)\n",
    "        np.delete(yTrain,count)\n",
    "        \n",
    "        xTrainAux = []\n",
    "        yTrainAux = []\n",
    "        for i in range(kParts):\n",
    "            for j in range(len(yTrain[i])):\n",
    "                yTrainAux.append(yTrain[i][j])\n",
    "        for i in range(kParts):\n",
    "            for j in range(len(xTrain[i])):\n",
    "                xTrainAux.append(xTrain[i][j])\n",
    "        xTrain = np.stack(xTrainAux)\n",
    "        yTrain = np.stack(yTrainAux)\n",
    "        \n",
    "        predicted = algorithm(xTrain, yTrain, xTest,  *args)\n",
    "        for i in range(len(predicted)):\n",
    "            aux = np.array([round(x) for x in yTest[i]])\n",
    "            aux = np.where(aux < 0, 0, aux)\n",
    "            print(\"Predicted: \",predicted[i],\"Actual: \", aux)\n",
    "        accuracy = np.array([x - y for x, y in zip(predicted, aux)])/kParts\n",
    "        scores.append(accuracy) \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_logistic_regression(xTrain, yTrain, xTest, alpha, epochs): \n",
    "    coef, m = gradient_descent(xTrain, yTrain, epochs, alpha)\n",
    "    return(predict_logistic_regression_binary(xTest, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_logistic_regression(xTrain, yTrain, xTest, alpha, epochs): \n",
    "    coef, m = stochastic_gradient_descent(xTrain, yTrain, epochs, alpha)\n",
    "    return(predict_logistic_regression_binary(xTest, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_logistic_regression_multiclass(xTrain, yTrain, xTest, alpha, epochs): \n",
    "    #xTrain, yTrain = normalization(xTrain, yTrain)\n",
    "    coef, mse = gradient_descent_multiclass(xTrain, yTrain, epochs, alpha)\n",
    "    return(predict_multiclass_logistic_regression(xTest, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_logistic_regression_multiclass(xTrain, yTrain, xTest, alpha, epochs): \n",
    "    #xTrain, yTrain = normalization(xTrain, yTrain)\n",
    "    coef, mse = stochastic_gradient_descent_multiclass(xTrain, yTrain, epochs, alpha)\n",
    "    return(predict_multiclass_logistic_regression(xTest, coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_x = np.array(data_table[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n",
    "vector_y = np.array(data_table['flower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_x, vector_y = normalization(matrix_x, vector_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(matrix_x, vector_y, epochs, alpha):\n",
    "    matrix_x = np.insert(matrix_x, 0, 1, axis =1)\n",
    "    w_matrix = np.ones((matrix_x.shape[1],), dtype=float)\n",
    "    y_predicted = matrix_x.dot(w_matrix)\n",
    "    mse = []\n",
    "    for epoch in range(epochs):\n",
    "        somatorio = 0\n",
    "        for i in range(matrix_x.shape[0]):\n",
    "            somatorio += (vector_y[i] - sigmoide(y_predicted[i])) * matrix_x[i]\n",
    "\n",
    "        mse.append((-1/matrix_x.shape[0]) * somatorio)\n",
    "        w_matrix = w_matrix + (alpha/matrix_x.shape[0])*somatorio\n",
    "        y_predicted = matrix_x.dot(w_matrix)\n",
    "\n",
    "    return w_matrix, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gd, mse = gradient_descent(matrix_x, vector_y, 9000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.41945565,  4.21455704, -2.48377345,  5.53228917,  5.49970277])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de3hc9X3n8fdXMxpJo/vNN10sGWyCTbgah4SWpKSA07R2ssm2TpsGt5vSp1mWNnnSPrDtk2zJs7vdbNqy3aVNgZCEpl2TeGlqWlJi2lwaSIhFsAHbMdjGF/kqS7as+2ik7/4xR/ZIyPbYkjzSOZ/X88wz5/zOmZnvOR5/dOZ3fnPG3B0REQmvgnwXICIiM0tBLyIScgp6EZGQU9CLiIScgl5EJOTi+S5gorq6Om9pacl3GSIic8pLL710wt3rJ1s264K+paWFtra2fJchIjKnmNn+cy1T142ISMgp6EVEQk5BLyIScgp6EZGQU9CLiIScgl5EJOQU9CIiIZdT0JvZajPbZWa7zez+c6zzy2a2w8y2m9nfZbXfbWZvBLe7p6vwiboHhnnoudfZdvDUTL2EiMicdMEvTJlZDHgYuANoB7aY2SZ335G1zlLgAeBWdz9pZvOC9hrgs8BKwIGXgseenO4NMYOHnnuDZCLGdU1V0/30IiJzVi5H9KuA3e6+191TwAZg7YR1fgt4eCzA3f140H4XsNndu4Jlm4HV01P6eBXFhVQUx2k/OTATTy8iMmflEvQNwMGs+fagLdsyYJmZPW9mPzKz1RfxWMzsHjNrM7O2jo6O3KufoLE6qaAXEZkgl6C3Sdom/v5gHFgKvAf4CPCYmVXl+Fjc/RF3X+nuK+vrJ70mT04aq0toP9l/yY8XEQmjXIK+HWjKmm8EDk+yzj+4+7C7vwnsIhP8uTx22jRUl3Do5AD6HVwRkbNyCfotwFIzazWzBLAO2DRhnW8CPwdgZnVkunL2As8Cd5pZtZlVA3cGbTOisTpJX2qEU/3DM/USIiJzzgVH3bh72szuJRPQMeBxd99uZg8Cbe6+ibOBvgMYAX7f3TsBzOxzZP5YADzo7l0zsSGQ6boBaD85QHVpYqZeRkRkTsnpevTu/gzwzIS2z2RNO/Cp4DbxsY8Dj0+tzNycDfp+3t5YeTleUkRk1gvVN2Mbq5MAHDqlkTciImNCFfSVJYWUF2ksvYhItlAFPWRG3miIpYjIWaELen1pSkRkvBAGvcbSi4hkC2XQ9wylOT2QzncpIiKzQiiDHuCg+ulFRIBQBn1miKX66UVEMkIY9Jkjeo2lFxHJCF3QV5YUUlYU1xBLEZFA6ILezGioKlHXjYhIIHRBD2PXpVfQi4hAqINeXTciIhDaoE/SM5ime0DXpRcRCWnQByNv1H0jIhLOoG/Iui69iEjUhTLo9aUpEZGzQhn01clCkomYgl5EhJAGvZnRVJ3U9W5ERAhp0AM01SQ52KWgFxEJbdAvrk1yoKtf16UXkcgLbdA31yTpT41wojeV71JERPIq1EEPcKCrL8+ViIjkV05Bb2arzWyXme02s/snWb7ezDrMbGtw+3jWss+b2XYz22lmf2FmNp0bcC7NtWNBr356EYm2+IVWMLMY8DBwB9AObDGzTe6+Y8KqT7r7vRMe+y7gVuDaoOkHwLuB706x7gtqqCrBDA50aoiliERbLkf0q4Dd7r7X3VPABmBtjs/vQDGQAIqAQuDYpRR6sYoLYyyoKGa/um5EJOJyCfoG4GDWfHvQNtGHzOwVM9toZk0A7v5D4DvAkeD2rLvvnPhAM7vHzNrMrK2jo+OiN+JcmjXEUkQkp6CfrE994pjFp4EWd78WeA74KoCZXQlcDTSS+eNwu5nd9pYnc3/E3Ve6+8r6+vqLqf+8mmuS7O9U0ItItOUS9O1AU9Z8I3A4ewV373T3oWD2UeCmYPqDwI/cvdfde4FvAbdMreTcNdckOd4zxEBq5HK9pIjIrJNL0G8BlppZq5klgHXApuwVzGxh1uwaYKx75gDwbjOLm1khmROxb+m6mSljI290FUsRibILBr27p4F7gWfJhPTX3X27mT1oZmuC1e4LhlBuA+4D1gftG4E9wKvANmCbuz89zdtwTmNj6dV9IyJRdsHhlQDu/gzwzIS2z2RNPwA8MMnjRoDfnmKNl+zsl6YU9CISXaH9ZixATWmC0kRMQS8ikRbqoDczmmtLFfQiEmmhDnqA5poSBb2IRFoEgj5zueLRUV2uWESiKfxBX1tKKj3K8Z6hC68sIhJC4Q96jbwRkYiLTNDv79TFzUQkmkIf9A1VJRSYjuhFJLpCH/SJeAEN1SW8eUJH9CISTaEPeoDWujL2qetGRCIqGkFfm2TfiX7cNcRSRKInEkHfUldK71Cajl4NsRSR6IlE0LfWlQKw74ROyIpI9EQs6NVPLyLRE4mgb6gqIV5g7FXQi0gERSLo47ECmmuTOqIXkUiKRNADtNaWaoiliERSZIK+pa6UN0/06SqWIhI5kQn61rpShtKjHD09mO9SREQuq0gFPWjkjYhET2SCviUIeo28EZGoiUzQL6wopiheoCN6EYmcyAR9QYHRopE3IhJBOQW9ma02s11mttvM7p9k+Xoz6zCzrcHt41nLms3s22a208x2mFnL9JV/cVrqkuq6EZHIiV9oBTOLAQ8DdwDtwBYz2+TuOyas+qS73zvJUzwB/Fd332xmZcDoVIu+VK11ZfzrT4+THhklHovMhxkRibhc0m4VsNvd97p7CtgArM3lyc1sORB3980A7t7r7nm7slhrXZLhEefwKQ2xFJHoyCXoG4CDWfPtQdtEHzKzV8xso5k1BW3LgFNm9pSZvWxm/zP4hDCOmd1jZm1m1tbR0XHRG5Gr1royAPac6J2x1xARmW1yCXqbpG3i10ufBlrc/VrgOeCrQXsc+Fng08DNwBJg/VuezP0Rd1/p7ivr6+tzLP3iXVGfGWK557iCXkSiI5egbweasuYbgcPZK7h7p7uP/arHo8BNWY99Oej2SQPfBG6cWsmXrrasiOpkIXs6FPQiEh25BP0WYKmZtZpZAlgHbMpewcwWZs2uAXZmPbbazMYO028HJp7EvayunFfGbh3Ri0iEXDDogyPxe4FnyQT41919u5k9aGZrgtXuM7PtZrYNuI+ge8bdR8h02/yLmb1Kphvo0enfjNwp6EUkai44vBLA3Z8BnpnQ9pms6QeAB87x2M3AtVOocVpdUV/Gyf5huvpS1JQm8l2OiMiMi9xg8ivmZUbe6KheRKIickF/Zb2CXkSiJXJB31BVQnFhgYJeRCIjckFfUGAsqSvTEEsRiYzIBT1o5I2IREtkg/7QqQH6U+l8lyIiMuMiG/QAezt0yWIRCb9IBv0Vwcgb9dOLSBREMuhb6pIUmIZYikg0RDLoi+IxFteWKuhFJBIiGfSQ6b5R0ItIFEQ26JfNL+PNE32k0nn7ZUMRkcsiskF/1YJy0qPOXv3alIiEXKSDHmDX0Z48VyIiMrMiG/RL6sqIFxg/VdCLSMhFNugT8QKuqC/jdQW9iIRcZIMeYNmCch3Ri0joRTro37agnEOnBugZHM53KSIiMybSQX/V/MwJ2dePaeSNiIRXtINeI29EJAIiHfQNVSWUJmLsOno636WIiMyYSAd9QYGxbEE5u47piF5EwivSQQ+ZfvpdR3tw93yXIiIyIxT0C8o52T9MR89QvksREZkROQW9ma02s11mttvM7p9k+Xoz6zCzrcHt4xOWV5jZITP7P9NV+HQZOyGr8fQiElYXDHoziwEPA+8DlgMfMbPlk6z6pLtfH9wem7Dsc8D3plztDLh6QQUAO4/ohKyIhFMuR/SrgN3uvtfdU8AGYG2uL2BmNwHzgW9fWokzq7o0waLKYrYfVtCLSDjlEvQNwMGs+fagbaIPmdkrZrbRzJoAzKwA+FPg98/3AmZ2j5m1mVlbR0dHjqVPn+WLKtl+uPuyv66IyOWQS9DbJG0Th6g8DbS4+7XAc8BXg/ZPAM+4+0HOw90fcfeV7r6yvr4+h5Km14pFFew90Ud/Kn3ZX1tEZKblEvTtQFPWfCNwOHsFd+9097FhK48CNwXT7wTuNbN9wBeAj5nZn0yp4hmwYlEF7rDziE7Iikj45BL0W4ClZtZqZglgHbApewUzW5g1uwbYCeDuv+buze7eAnwaeMLd3zJqJ9+uaagEYIe6b0QkhOIXWsHd02Z2L/AsEAMed/ftZvYg0Obum4D7zGwNkAa6gPUzWPO0W1hZTHWyUCdkRSSULhj0AO7+DPDMhLbPZE0/ADxwgef4CvCVi67wMjAzViyq5DUd0YtICEX+m7FjViyq4PWjvQyPjOa7FBGRaaWgDyxfVEFqZJQ3dG16EQkZBX1gxaLMCVmNpxeRsFHQB1rrSkkmYjohKyKho6APxAqMqxdW6IheREJHQZ/l7Q2VvHboNGmdkBWREFHQZ7mhuYqB4RHeOK4TsiISHgr6LNc1VgGw7eCpPFciIjJ9FPRZFtcmqSwpZFu7gl5EwkNBn8XMuK6piq0HdUJWRMJDQT/B9Y2V7Dp6WpcsFpHQUNBPcF1TFaMOrx3SeHoRCQcF/QTXNemErIiEi4J+grqyIhqrS9iqE7IiEhIK+klc11SlI3oRCQ0F/SSub6yi/eQAHT1DF15ZRGSWU9BP4sbFmX76nxw4medKRESmTkE/iWsaKknEC2jb15XvUkREpkxBP4mieIzrGivZsk9H9CIy9ynoz2FlSw2vHepmIDWS71JERKZEQX8ON7dUkx51tmr0jYjMcQr6c7ipuQZA/fQiMucp6M+hMlnIVfPL2bJf/fQiMrflFPRmttrMdpnZbjO7f5Ll682sw8y2BrePB+3Xm9kPzWy7mb1iZr8y3Rswk1a2VPOT/ScZGfV8lyIicskuGPRmFgMeBt4HLAc+YmbLJ1n1SXe/Prg9FrT1Ax9z9xXAauAhM6uaptpn3M0tNfQOpfnpUV3gTETmrlyO6FcBu919r7ungA3A2lye3N1fd/c3gunDwHGg/lKLvdxWtlQDsOVN9dOLyNyVS9A3AAez5tuDtok+FHTPbDSzpokLzWwVkAD2TLLsHjNrM7O2jo6OHEufeY3VSRqrS/jh3s58lyIicslyCXqbpG1ip/XTQIu7Xws8B3x13BOYLQT+BvgNdx99y5O5P+LuK919ZX397Drgv/WKOn64p1P99CIyZ+US9O1A9hF6I3A4ewV373T3sSuAPQrcNLbMzCqAfwL+yN1/NLVyL793XVnL6cE0Ow6rn15E5qZcgn4LsNTMWs0sAawDNmWvEByxj1kD7AzaE8DfA0+4+zemp+TL651X1ALw/J4Tea5EROTSXDDo3T0N3As8SybAv+7u283sQTNbE6x2XzCEchtwH7A+aP9l4DZgfdbQy+unfStm0LzyYpbOK+P53Qp6EZmb4rms5O7PAM9MaPtM1vQDwAOTPO5rwNemWGPe3XplHRu2HCCVHiUR13fMRGRuUWrl4F1X1DI4PMrLuj69iMxBCvocvGNJLQUGL+zRMEsRmXsU9DmoLCnk7Q2V/ED99CIyBynoc/Tuq+bx8oGTnOpP5bsUEZGLoqDP0c9dVc+ow/ff0FG9iMwtCvocXdtYRU1pgu/+9Hi+SxERuSgK+hzFCox3L6vnu693MKrLIYjIHKKgvwjvuaqerr4UrxzqzncpIiI5U9BfhNuW1lNg8K/qvhGROURBfxGqSxPc0FzNdxT0IjKHKOgv0u1vm8erh7o50j2Q71JERHKioL9Id61YAMC3tx/LcyUiIrlR0F+kK+eVsXReGd967Ui+SxERyYmC/hKsvmYBP36zi87eoQuvLCKSZwr6S3DXigWMOmzeoe4bEZn9FPSXYMWiCppqSvjn7UfzXYqIyAUp6C+BmbF6xQKe332C7oHhfJcjInJeCvpL9P5rFzE84jz7mo7qRWR2U9BfousaK2mtK+Wpl9vzXYqIyHkp6C+RmfGB6xv40d4uDp3Sl6dEZPZS0E/BB29oAGDT1sN5rkRE5NwU9FPQXJvkpsXV/P3L7bjr0sUiMjsp6KfoAzc08PqxXnYcOZ3vUkREJpVT0JvZajPbZWa7zez+SZavN7MOM9sa3D6etexuM3sjuN09ncXPBr907UIS8QKe3HIw36WIiEzqgkFvZjHgYeB9wHLgI2a2fJJVn3T364PbY8Fja4DPAu8AVgGfNbPqaat+FqhKJvjFty/k739yiP5UOt/liIi8RS5H9KuA3e6+191TwAZgbY7Pfxew2d273P0ksBlYfWmlzl6/+o5meobSPL1NJ2VFZPbJJegbgOx+ifagbaIPmdkrZrbRzJou5rFmdo+ZtZlZW0dHR46lzx43La5m2fwy/vbFA/kuRUTkLXIJepukbeIQk6eBFne/FngO+OpFPBZ3f8TdV7r7yvr6+hxKml3MjF97x2Jeae/m1Xb9nqyIzC65BH070JQ13wiM66Nw9053H7tm76PATbk+Niw+eGMDJYUxvvzCm/kuRURknFyCfguw1MxazSwBrAM2Za9gZguzZtcAO4PpZ4E7zaw6OAl7Z9AWOhXFhfzKzU08ve0wR7sH812OiMgZFwx6d08D95IJ6J3A1919u5k9aGZrgtXuM7PtZrYNuA9YHzy2C/gcmT8WW4AHg7ZQ+g8/08rIqOuoXkRmFZtt3+hcuXKlt7W15buMS/Yf/+4nfH9XBy88cDvlxYX5LkdEIsLMXnL3lZMt0zdjp9k9P7uEnqE0G36sL1CJyOygoJ9m1zVV8c4ltfz19/cykBrJdzkiIgr6mfCpO5dxoneIJ364L9+liIgo6GfCzS013Lasni9+bw+9Q7osgojkl4J+hnzqjmWc7B/m8R9oBI6I5JeCfoZc31TFHcvn89ff28PxHo2rF5H8UdDPoP/8C1eTGhnl8/+8K9+liEiEKehnUGtdKb/5M61sfKmdbQdP5bscEYkoBf0M+0+3L6W+vIjPbNrOyOjs+nKaiERDPN8FhF1ZUZw/ev/V/O6GrTz+gzf5rduW5LskEblE6ZFRBtOjDA6PZN1Gz9wPjGs/u2xgbDp97mVDwyMsm1/OF3/9pgsXcpEU9JfBmusW8fS2I3zh27t479XzWFJflu+SRELJ3RlKj9KfGqE/lWYgNRJMjzAwnD47feY+aBsea8vMDw6PX68/lWZgeIThkUv7VB4vMEoKYxQVxiguLKC4MEZJMF1WFKeuLEZxYYwr6kuneY8Erz8jzyrjmBn/7YPX8PN/9j3+YOMrbLjnFuIx9ZqJuDv9qRF6h9L0DqXpO3M/Qu/QML1DI/RltfcOpulLpce192UF+sDwCBd7+a5kIkYyEaMkESNZGM/cJ2IsrCykJBEnWZhZVpI4G85nQ/tsW/Z0UTxYlohRHC/I+/93Bf1lMq+imAfXXsPvPbmVh557g0/fdVW+SxKZkqH0CD2DaU4PDHN6ME3P4DCnB9KcHhw+M90zmFmWHeJj031DI/Sl0jkFsxmUJeKUFsUpLYpRVpSZrilNUpqIZQJ5XGDHSCbOhnbmPrNOSWEsWDdOcWEBZpP9PlK4KOgvow/c0MALe07w8Hd3c3NrDe9eNvd+TUvCw905PZimu3+Yk/0pTg0Mc6o/dSa4z9wPDnN6YDgT6lkBPpQePe/zFxhUlBRSVhQ/c6tOJmiqSZ4J7bKiWBDeccqL45SeaT8b6GXFcUoKY5EI5JmioL/M/njNNWw72M0nn9zKNz9xK821yXyXJHPcWPfHyf4Up/qHOZUd3H2Z+5P9qQmBPkz3wPB5R4IVxQuoKCmkvDhORXHmvqG6hIriQiqK41SUZO7LiwupKBlb5+x0MqFwni10Pfo82NvRywf/8gXqyhI89Tu3UpnUdetlvMHhETr7UnT2DgX3memuvhQnelN09mWmO3tTnOgdOu/RdWkiRlUyQVWyMLglqCoppPpMWzBfWkhlSaatvDhOUTx2GbdYpup816PXEX0eLKkv45Ffv4lf/9KP+e2vtfGV31hFcaH+U4Xd8MgoJ3qHOH56iOM9Qxw7PcjxniE6egbp6MmEd2dviq6+1DkvhpeIF1BXmqC2rIjasgRXziujrqyImtIENckElcnsAC+ksqRQgS0K+nx5x5JaPv/ha/m9J7fyO197ib/66E0K+zlqeGSUY6cHOXZ6iONBeB/vGRwX6B09Q3T1p95y4tEMakuLqCtLUF9eRHNNktrSTIjXZgX62HSpukPkEijo8+gDNzQwODzC/U+9qrCfpUZGnY6eIQ53D3Dk1CBHugc4PHbfPciRUwN09A69JcBjBUZ9WRHzKoporC7hhuZq5pUXMb+imHnlmfZ55cXUlSXyPvROwk9Bn2frVjUDcP9Tr/LRx17kkY+tpKY0keeqomNk1Dl8aoD9nf3s6+zjYFf/mQA/0j3IsdODpCecsCwpjLGwqphFlSUsW1bPwqoSFlUWM78yCPHyYmpKE8QKdOQts4OCfhZYt6qZ8uJCPvX1rXzwL5/nS3ev5Mp55fkuKzRS6VHaT/azv7Of/Z197Avu93f2c/Bk/7hvOyZiBSyoLGZhZTGrWmtYWFl8JsgXVpawqKqYypJCdZ/InKKgnyXef+1CFlYVc88TbfzS/36eP16zgn+/slGBkqPB4REOdPWz70QmwPd39Z05Sj90coDsg/LSRIzFtaW8bWE5d12zgJbaJM01pbTUJZlfXkyBjsQlZDS8cpY5dnqQTz65lRf2dLJ6xQL+y5oVLKgszndZs0LvUPrMkfi+zj72nzgb6Ee6x/+4S1WykMU1SRbXltJSG9zXZQK9riyhP6ASOucbXplT0JvZauB/ATHgMXf/k3Os92HgG8DN7t5mZoXAY8CNZD49POHu//18rxX1oIdMv/Gj/7aXP9/8OvEC43d/fikfe2dLJE7UdvcPs6+zLxPkY4Hemel2OdE7NG7durKizNF4bZKW2lIWZ91XJXWeQ6JlSkFvZjHgdeAOoB3YAnzE3XdMWK8c+CcgAdwbBP2vAmvcfZ2ZJYEdwHvcfd+5Xk9Bf9aBzn4+u+k1vrOrg/kVRXziPVfyKzc3zenAd3dO9KY40NXHvhPj+8z3dfbTPTA8bv2FlcVZAZ4J8cXBEXpZkXoeRcZM9QtTq4Dd7r43eLINwFoyoZ3tc8DngU9ntTlQamZxoARIAacvrvzoaq5N8vj6m/nh3k4e2vwGn920nT/99i7+3Y2NrFvVxFXzy2dlF8ToqHOsZ5B9J/ozgT4W5EGw96VGzqxbYNBQXUJLbSm/dN3CcYHeXJOc03/URGaLXIK+ATiYNd8OvCN7BTO7AWhy9380s+yg30jmj8IRIAl80t27Jr6Amd0D3APQ3Nx8URsQdmbGu66o451Latmy7yRf+9F+/vbF/XzlhX201pVy5/L53Lasnuubqii9jEe4vUNpDgSjVg529XMg69beNUBq5OxX8gtjRlNNksU1SVa11mT6zOtKaaktpaGqhERc48hFZlIuyTDZIeOZ/h4zKwD+HFg/yXqrgBFgEVAN/JuZPTf26eDMk7k/AjwCma6bnCqPGDNjVWsNq1pr6OxdzrdeO8q3dxzj8eff5K+/v5dYgXH1wnKuXlDBkvoyrqgvZVFVCfXlma/HF+bwpZzhkVG6z1zwKsXJvmGO9QxyrHuQo6cHOXp66Mz0xC6W8uI4i2uTvG1BOXcsn09T9dn+8kVVJRpTLpJHuQR9O9CUNd8IHM6aLweuAb4bdCMsADaZ2RrgV4F/dvdh4LiZPQ+sBMYFvVyc2rIiPnrLYj56y2J6Bof5yYFTvLSvi5cOnOR7r3fwjZfa3/KY8qI4RcEPIiTiBZhlgj2VHmV4xBkaHhnXpZLNLHPic0FFMU01SW5urWZhZUmmr7ymlOaapC7MJjKL5RL0W4ClZtYKHALWkQlwANy9G6gbmzez7wKfDk7Gvhe43cy+Rqbr5hbgoekrX8qLC3n3svpx17Y/PTjM3o4+jnYPcqJ3iBO9Q5zqHyYVBPtQepRRd4piBSTiBRQG95UlZy+ElZlOMK+8iPryopw+EYjI7HTBoHf3tJndCzxLZnjl4+6+3cweBNrcfdN5Hv4w8GXgNTJdQF9291emoW45j4riQq5vqhr/OUxEIktfmBIRCYHzDa/U53ERkZBT0IuIhJyCXkQk5BT0IiIhp6AXEQk5Bb2ISMgp6EVEQm7WjaM3sw5g/xSeog44MU3lzHXaF+Npf4yn/XFWGPbFYnevn2zBrAv6qTKztnN9aSBqtC/G0/4YT/vjrLDvC3XdiIiEnIJeRCTkwhj0j+S7gFlE+2I87Y/xtD/OCvW+CF0fvYiIjBfGI3oREcmioBcRCbnQBL2ZrTazXWa228zuz3c9M8HMmszsO2a208y2m9nvBu01ZrbZzN4I7quDdjOzvwj2yStmdmPWc90drP+Gmd2dr22aDmYWM7OXzewfg/lWM3sx2LYnzSwRtBcF87uD5S1Zz/FA0L7LzO7Kz5ZMnZlVmdlGM/tp8D55Z1TfH2b2yeD/yWtm9n/NrDiy7w13n/M3Mr98tQdYAiSAbcDyfNc1A9u5ELgxmC4HXgeWA58H7g/a7wf+RzD9C8C3yPy61y3Ai0F7DZnf7a0h86Pte4HqfG/fFPbLp4C/A/4xmP86sC6Y/iLwO8H0J4AvBtPrgCeD6eXBe6YIaA3eS7F8b9cl7ouvAh8PphNAVRTfH0AD8CZQkvWeWB/V90ZYjuhXAbvdfa+7p4ANwNo81zTt3P2Iu/8kmO4BdpJ5Q68l8x+c4P4DwfRa4AnP+BFQZWYLgbuAze7e5e4ngc3A6su4KdPGzBqB9wOPBfMG3A5sDFaZuD/G9tNG4L3B+muBDe4+5O5vArvJvKfmFDOrAG4DvgTg7il3P0V03x9xoMTM4mR+s/oIEX1vhCXoG4CDWfPtQVtoBR8tbwBeBOa7+xHI/DEA5gWrnWu/hGl/PQT8ATAazNcCp9w9Hcxnb9uZ7Q6Wdwfrh2V/LAE6gC8HXVmPmVkpEXx/uPsh4AvAATIB3w28RETfG2EJepukLbTjRs2sDPh/wO+5++nzrTpJm5+nfU4xs18Ejrv7S9nNk6zqF1gWiv1B5gj2RuCv3P0GoI9MV825hHZ/BOch1pLpblkElFM+CKMAAAG0SURBVALvm2TVSLw3whL07UBT1nwjcDhPtcwoMyskE/J/6+5PBc3Hgo/cBPfHg/Zz7Zew7K9bgTVmto9Md93tZI7wq4KP6zB+285sd7C8EugiPPujHWh39xeD+Y1kgj+K74+fB9509w53HwaeAt5FRN8bYQn6LcDS4Ix6gszJlE15rmnaBX2GXwJ2uvufZS3aBIyNjLgb+Ies9o8FoytuAbqDj+7PAneaWXVw5HNn0DanuPsD7t7o7i1k/s3/1d1/DfgO8OFgtYn7Y2w/fThY34P2dcHIi1ZgKfDjy7QZ08bdjwIHzeyqoOm9wA6i+f44ANxiZsng/83YvojkeyPvZ4On60ZmBMHrZM6K/2G+65mhbfwZMh8bXwG2BrdfINOX+C/AG8F9TbC+AQ8H++RVYGXWc/0mmRNLu4HfyPe2TcO+eQ9nR90sIfOfcTfwDaAoaC8O5ncHy5dkPf4Pg/20C3hfvrdnCvvheqAteI98k8yomUi+P4A/Bn4KvAb8DZmRM5F8b+gSCCIiIReWrhsRETkHBb2ISMgp6EVEQk5BLyIScgp6EZGQU9CLiIScgl5EJOT+P4lyc0fKhKdWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cost(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000 \n",
    "alpha =  0.001\n",
    "kParts = 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. , -0.2]),\n",
       " array([ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. , -0.2]),\n",
       " array([ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. , -0.2]),\n",
       " array([ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. , -0.2]),\n",
       " array([ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. , -0.2])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kFoldCrossValidation(matrix_x, vector_y, kParts, gradient_logistic_regression, alpha, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predctions_gd = predict_logistic_regression_binary(matrix_x, w_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(matrix_x, vector_y, epochs, alpha):\n",
    "    matrix_x = np.insert(matrix_x, 0, 1, axis =1)\n",
    "    w_matrix = np.ones((matrix_x.shape[1],), dtype=float)\n",
    "    y_predicted = matrix_x.dot(w_matrix)\n",
    "    data =np.append(matrix_x, np.split(vector_y, matrix_x.shape[0], axis=0), axis=1)\n",
    "    mse = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        erro = 0\n",
    "        somatorio = 0\n",
    "        for i in range(matrix_x.shape[0]):\n",
    "            w_matrix  = w_matrix + alpha * (vector_y[i] - sigmoide(y_predicted[i])) * matrix_x[i]\n",
    "            somatorio += (vector_y[i] - sigmoide(y_predicted[i])) * matrix_x[i]\n",
    "        \n",
    "        mse.append((-1/matrix_x.shape[0]) * somatorio)        \n",
    "        data = np.random.permutation(data)\n",
    "        matrix_x = data[: ,0:matrix_x.shape[1]]\n",
    "        vector_y = data[:,matrix_x.shape[1]]\n",
    "        \n",
    "        y_predicted = matrix_x.dot(w_matrix)  \n",
    "    \n",
    "    return w_matrix, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gde, mse = stochastic_gradient_descent(matrix_x, vector_y, 10000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-498.47703627,  364.70980605, -342.06964503,  486.27425106,\n",
       "        481.44881975])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_gde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predctions_gde = predict_logistic_regression_binary(matrix_x, w_gde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  0.0 Actual:  0.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  1.0 Actual:  1.0\n",
      "Predicted:  0.0 Actual:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kFoldCrossValidation(matrix_x, vector_y, kParts, stochastic_logistic_regression, alpha, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_x_multiclass = np.array(iris_data_multiclass[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n",
    "vector_y_multiclass = np.array(iris_data_multiclass[['flower1', 'flower2', 'flower3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_x_multiclass, vector_y_multiclass = normalization(matrix_x_multiclass, vector_y_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_multiclass(matrix_x, vector_y, epochs, alpha):\n",
    "    \n",
    "    matrix_x = np.insert(matrix_x, 0, 1, axis =1)\n",
    "    \n",
    "    size = (vector_y.shape[1], matrix_x.shape[1])\n",
    "    w_matrix = np.ones(size, dtype=float)\n",
    "\n",
    "    mse = []\n",
    "    for k in range(w_matrix.shape[0]): \n",
    "        y_aux = w_matrix[k].dot(np.transpose(matrix_x))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            somatorio = 0\n",
    "            for i in range(matrix_x.shape[0]):\n",
    "                _sum = 0\n",
    "                for j in range(w_matrix.shape[0]):\n",
    "                    _sum += np.exp(w_matrix[j].dot(matrix_x[i]))\n",
    "                \n",
    "                err = np.exp(y_aux[i])/_sum\n",
    "                somatorio += (vector_y[i][k] - err) * matrix_x[i]\n",
    "            \n",
    "            mse.append((-1/matrix_x.shape[0]) * somatorio)\n",
    "            w_matrix[k] = w_matrix[k] + (alpha/matrix_x.shape[0])*somatorio\n",
    "            y_aux = w_matrix[k].dot(np.transpose(matrix_x))\n",
    "\n",
    "\n",
    "    return w_matrix, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gd_m, mse = gradient_descent_multiclass(matrix_x_multiclass, vector_y_multiclass, 10000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-32.43258678, -37.07709576,  32.77808385, -48.05638174,\n",
       "        -46.1842269 ],\n",
       "       [-21.05575389,   3.25982491, -20.42469787,   8.55694086,\n",
       "          2.72640771],\n",
       "       [-45.15104259,  26.79114703,  -7.78928992,  34.28823158,\n",
       "         38.36118226]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_gd_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gd_m = predict_multiclass_logistic_regression(matrix_x_multiclass, w_gd_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_multiclass(matrix_x, vector_y, epochs, alpha):\n",
    "    \n",
    "    matrix_x = np.insert(matrix_x, 0, 1, axis =1)\n",
    "\n",
    "    size = (vector_y.shape[1], matrix_x.shape[1])    \n",
    "    w_matrix = np.ones(size, dtype=float)\n",
    "    #y_chapeu = matrix_x.dot(w_matrix)\n",
    "    #data =np.append(matrix_x, np.split(vector_y, matrix_x.shape[0], axis=0), axis=1)\n",
    "\n",
    "    data =np.append(matrix_x, vector_y, axis=1)\n",
    "    \n",
    "    mse = []\n",
    "\n",
    "    for k in range(w_matrix.shape[0]):\n",
    "        y_aux = w_matrix[k].dot(np.transpose(matrix_x))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            #somatorio = 0\n",
    "            for i in range(matrix_x.shape[0]):\n",
    "                _sum = 0\n",
    "                for j in range(w_matrix.shape[0]):\n",
    "                    _sum += np.exp(w_matrix[j].dot(matrix_x[i]))\n",
    "        \n",
    "                err = np.exp(y_aux[i])/_sum\n",
    "                \n",
    "                w_matrix[k] = w_matrix[k] + alpha * (vector_y[i][k] - err) * matrix_x[i]\n",
    "                #somatorio += (vector_y[i] - sigmoide(y_chapeu[i])) * matrix_x[i]\n",
    "\n",
    "            #mse.append((-1/matrix_x.shape[0]) * somatorio)        \n",
    "            data = np.random.permutation(data)\n",
    "            matrix_x = data[: ,0:matrix_x.shape[1]]\n",
    "            vector_y = data[:,matrix_x.shape[1]:]\n",
    "            y_aux = w_matrix[k].dot(np.transpose(matrix_x))\n",
    "            \n",
    "                \n",
    "    return w_matrix, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix_x_multiclass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-589cd07c5d9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw_gde_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstochastic_gradient_descent_multiclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix_x_multiclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_y_multiclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'matrix_x_multiclass' is not defined"
     ]
    }
   ],
   "source": [
    "w_gde_m, mse = stochastic_gradient_descent_multiclass(matrix_x_multiclass, vector_y_multiclass, 10000, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w_gde_m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-eded7a73c974>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw_gde_m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'w_gde_m' is not defined"
     ]
    }
   ],
   "source": [
    "w_gde_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gde_m = predict_multiclass_logistic_regression(matrix_x_multiclass, w_gde_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0. , -0.2, -0.2],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0.2]]), array([[ 0. , -0.2, -0.2],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0.2]]), array([[ 0. , -0.2, -0.2],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0.2]]), array([[ 0. , -0.2, -0.2],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0.2]]), array([[ 0. , -0.2, -0.2],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0.2]])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kFoldCrossValidationMulticlass(matrix_x_multiclass, vector_y_multiclass, kParts, gradient_logistic_regression_multiclass, alpha, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [0. 1. 0.] Actual:  [0. 1. 0.]\n",
      "Predicted:  [0. 0. 1.] Actual:  [0. 0. 1.]\n",
      "Predicted:  [1. 0. 0.] Actual:  [1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.2, -0.2,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0.2]]), array([[-0.2, -0.2,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0.2]]), array([[-0.2, -0.2,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0.2]]), array([[-0.2, -0.2,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0.2]]), array([[-0.2, -0.2,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0.2]])]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kFoldCrossValidationMulticlass(matrix_x_multiclass, vector_y_multiclass, kParts, stochastic_logistic_regression_multiclass, alpha, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
